# AnyDataset - Raport z refactoringu (04.04.2025)

## Podsumowanie działań refaktoryzacyjnych

Podczas dzisiejszej sesji przeprowadziliśmy znaczącą refaktoryzację aplikacji AnyDataset, skupiając się na ulepszeniu zarządzania modelami AI i interfejsu użytkownika. Poniżej przedstawiamy kluczowe zmiany i dodatki.

### 1. Dynamiczne wykrywanie dostępnych modeli AI

Zaimplementowaliśmy mechanizm dynamicznego wykrywania dostępnych modeli AI na podstawie kluczy API obecnych w pliku .env:

- Stworzono nowy moduł `utils/models.py` do zarządzania informacjami o modelach
- Dodano funkcje do wykrywania dostępnych dostawców (Anthropic, OpenAI, Mistral, itd.)
- Zintegrowano dynamiczne wykrywanie modeli z interfejsem użytkownika
- Dodano domyślne ustawienia dla różnych dostawców modeli

```python
# Przykład nowej funkcjonalności wykrywania dostępnych modeli
def get_available_models(filter_by_api_keys: bool = True) -> Dict[str, Any]:
    """Get available models, optionally filtered by available API keys."""
    if not filter_by_api_keys:
        return ALL_MODELS
    
    available_models = {}
    for provider, config in ALL_MODELS.items():
        env_key = config.get("env_key")
        # For local models (like LM Studio), we don't strictly need a real API key
        is_local = provider == "lmstudio"
        
        if env_key and (os.getenv(env_key) or is_local):
            available_models[provider] = config
            logger.info(f"Provider {config['name']} is available")
        else:
            logger.info(f"Provider {config['name']} is not available (missing {env_key})")
    
    return available_models
```

### 2. Nowy interfejs przetwarzania plików (3-etapowy)

Zaprojektowano i zaimplementowano nowy, bardziej intuicyjny interfejs przetwarzania plików:

- Stworzono nowy endpoint `/process` i szablon HTML `process_file.html`
- Wprowadzono trójstopniowy proces przetwarzania:
  - Etap 1: Upload i automatyczne rozpoznanie formatu pliku
  - Etap 2: Generowanie i edycja słów kluczowych 
  - Etap 3: Konfiguracja opcji przetwarzania i wybór formatu docelowego
- Dodano dynamiczne aktualizacje UI za pomocą JavaScript
- Zaimplementowano podgląd plików (dla tekstowych typów)

### 3. Automatyczne generowanie słów kluczowych

Zaimplementowano funkcjonalność automatycznego generowania słów kluczowych:

- Dodano nowy endpoint `/extract-keywords` do procesowania plików
- Wykorzystano istniejące funkcje LLM do generowania słów kluczowych
- Umożliwiono edycję wygenerowanych słów kluczowych przed przetwarzaniem
- Zaktualizowano format JSON do przechowywania słów kluczowych w metadanych

```python
@app.post("/extract-keywords")
async def extract_keywords(file_info: Dict[str, str]):
    """Extract keywords from a file."""
    try:
        # Pobierz zawartość pliku
        file_path = file_info.get("file_path")
        records = parse_file(file_path, logger)
        
        # Ekstrahuj tekst z pierwszych kilku chunków
        text_content = " ".join([record.get("input", "") for record in records[:3]])
        
        # Wykorzystaj LLM do generowania słów kluczowych
        client = get_llm_client(get_default_provider())
        extracted_keywords = generate_keywords_from_text(text_content, client, max_keywords=10)
        
        return {"keywords": extracted_keywords}
    except Exception as e:
        logger.error(f"Error extracting keywords: {e}")
        return JSONResponse(status_code=500, content={"detail": f"Error: {str(e)}"})
```

### 4. Wsparcie dla reasoningu w przetwarzaniu

Dodano opcję włączania/wyłączania śladu rozumowania (reasoning) w generowanych danych:

- Zaktualizowano funkcję `convert_dataset` do obsługi flagi reasoning
- Zmodyfikowano skrypt `standard.py` by wykorzystywał reasoning
- Dodano parametr reasoningu do interfejsu użytkownika
- Przekazywanie opcji reasoning przez model pośredni

### 5. Format pośredni JSON

Zdefiniowano i zaimplementowano format pośredni JSON:

```json
{
  "instruction": "Pytanie/instrukcja",
  "input": "Kontekst z dokumentu",
  "output": "Odpowiedź/wynik",
  "metadata": {
    "source_file": "plik_źródłowy.pdf",
    "keywords": ["słowo1", "słowo2"]
  },
  "reasoning": "Analiza i tok rozumowania..."
}
```

### 6. Usprawnienia kodu i refaktoryzacja

- Zaktualizowano dokumentację w CLAUDE.md o nowe wzorce i funkcjonalności
- Usprawniono obsługę błędów i logowanie
- Poprawiono zagnieżdżanie callbacków postępu
- Usunięto zduplikowany kod związany z modelami

## Dalsze kroki

Na podstawie dzisiejszego refactoringu zdefiniowaliśmy dalszą wizję rozwoju w pliku `nextsteps.md`, która obejmuje:

1. Ulepszenie batch processingu z możliwością wykorzystania wielu modeli
2. Dodanie nowej zakładki "Prepare Training Data" 
3. Implementację podejścia hybrydowego do multimodalności
4. Wprowadzenie dodatkowych opcji konfiguracji modelu

## Uwagi techniczne

- Aktualny refactoring nie obejmuje kompleksowych zmian w strukturze folderów proponowanych w DATATREE.md
- Zachowano kompatybilność z istniejącymi funkcjami przetwarzania plików
- Uwzględniono dynamiczne wykrywanie kluczy API, które było brakującym elementem w poprzedniej wersji
- Wprowadzono podstawy pod przyszłe rozszerzenia (multimodalność, złożone transformacje danych)

## Wykorzystane technologie

- Python FastAPI - backend i API
- JavaScript (vanilla) - dynamiczne UI
- WebSockets - aktualizacje postępu w czasie rzeczywistym
- AsyncIO - równoległe przetwarzanie plików