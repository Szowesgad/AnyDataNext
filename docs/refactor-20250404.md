# AnyDataset - Raport z refactoringu (04.04.2025)

## Podsumowanie działań refaktoryzacyjnych

Podczas dzisiejszej sesji przeprowadziliśmy znaczącą refaktoryzację aplikacji AnyDataset, skupiając się na ulepszeniu zarządzania modelami AI, interfejsu użytkownika oraz przetwarzania wsadowego z obsługą wielu języków. Poniżej przedstawiamy kluczowe zmiany i dodatki.

### 1. Dynamiczne wykrywanie dostępnych modeli AI

Zaimplementowaliśmy mechanizm dynamicznego wykrywania dostępnych modeli AI na podstawie kluczy API obecnych w pliku .env:

- Stworzono nowy moduł `utils/models.py` do zarządzania informacjami o modelach
- Dodano funkcje do wykrywania dostępnych dostawców (Anthropic, OpenAI, Mistral, itd.)
- Zintegrowano dynamiczne wykrywanie modeli z interfejsem użytkownika
- Dodano domyślne ustawienia dla różnych dostawców modeli

```python
# Przykład nowej funkcjonalności wykrywania dostępnych modeli
def get_available_models(filter_by_api_keys: bool = True) -> Dict[str, Any]:
    """Get available models, optionally filtered by available API keys."""
    if not filter_by_api_keys:
        return ALL_MODELS
    
    available_models = {}
    for provider, config in ALL_MODELS.items():
        env_key = config.get("env_key")
        # For local models (like LM Studio), we don't strictly need a real API key
        is_local = provider == "lmstudio"
        
        if env_key and (os.getenv(env_key) or is_local):
            available_models[provider] = config
            logger.info(f"Provider {config['name']} is available")
        else:
            logger.info(f"Provider {config['name']} is not available (missing {env_key})")
    
    return available_models
```

### 2. Nowy interfejs przetwarzania plików (3-etapowy)

Zaprojektowano i zaimplementowano nowy, bardziej intuicyjny interfejs przetwarzania plików:

- Stworzono nowy endpoint `/process` i szablon HTML `process_file.html`
- Wprowadzono trójstopniowy proces przetwarzania:
  - Etap 1: Upload i automatyczne rozpoznanie formatu pliku
  - Etap 2: Generowanie i edycja słów kluczowych 
  - Etap 3: Konfiguracja opcji przetwarzania i wybór formatu docelowego
- Dodano dynamiczne aktualizacje UI za pomocą JavaScript
- Zaimplementowano podgląd plików (dla tekstowych typów)

### 3. Automatyczne generowanie słów kluczowych

Zaimplementowano funkcjonalność automatycznego generowania słów kluczowych:

- Dodano nowy endpoint `/extract-keywords` do procesowania plików
- Wykorzystano istniejące funkcje LLM do generowania słów kluczowych
- Umożliwiono edycję wygenerowanych słów kluczowych przed przetwarzaniem
- Zaktualizowano format JSON do przechowywania słów kluczowych w metadanych

### 4. Obsługa wielu języków

Dodano funkcjonalność wyboru języka dla danych wejściowych i wyjściowych:

- Opcje wyboru języka wejściowego (domyślnie: polski)
- Opcje wyboru języka wyjściowego (domyślnie: polski)
- Możliwość tłumaczenia danych między różnymi językami podczas przetwarzania
- Wykorzystanie skryptu translate.py do obsługi tłumaczeń

```python
@app.post("/extract-keywords")
async def extract_keywords(file_info: Dict[str, str]):
    """Extract keywords from a file."""
    try:
        # Pobierz zawartość pliku
        file_path = file_info.get("file_path")
        records = parse_file(file_path, logger)
        
        # Ekstrahuj tekst z pierwszych kilku chunków
        text_content = " ".join([record.get("input", "") for record in records[:3]])
        
        # Wykorzystaj LLM do generowania słów kluczowych
        client = get_llm_client(get_default_provider())
        extracted_keywords = generate_keywords_from_text(text_content, client, max_keywords=10)
        
        return {"keywords": extracted_keywords}
    except Exception as e:
        logger.error(f"Error extracting keywords: {e}")
        return JSONResponse(status_code=500, content={"detail": f"Error: {str(e)}"})
```

### 4. Wsparcie dla reasoningu w przetwarzaniu

Dodano opcję włączania/wyłączania śladu rozumowania (reasoning) w generowanych danych:

- Zaktualizowano funkcję `convert_dataset` do obsługi flagi reasoning
- Zmodyfikowano skrypt `standard.py` by wykorzystywał reasoning
- Dodano parametr reasoningu do interfejsu użytkownika
- Przekazywanie opcji reasoning przez model pośredni

### 5. Format pośredni JSON

Zdefiniowano i zaimplementowano format pośredni JSON:

```json
{
  "instruction": "Pytanie/instrukcja",
  "input": "Kontekst z dokumentu",
  "output": "Odpowiedź/wynik",
  "metadata": {
    "source_file": "plik_źródłowy.pdf",
    "keywords": ["słowo1", "słowo2"]
  },
  "reasoning": "Analiza i tok rozumowania..."
}
```

### 6. Nowy interfejs batch_process.html

Zaimplementowano nowy, zaawansowany interfejs do przetwarzania wsadowego:

- Utworzono nowy endpoint `/batch` i szablon HTML `batch_process.html`
- Dodano wsparcie dla przetwarzania wielu plików jednocześnie
- Wdrożono strategie "YoLo" (w pełni automatyczną) i "Paranoid" (z weryfikacją co X plików)
- Zaimplementowano obsługę wielu modeli pracujących równolegle
- Dodano strategie alokacji zadań: round-robin, file-size-based i file-type-based
- Zaimplementowano wizualizację postępu i szacowanie kosztów/czasu przetwarzania

### 7. Wielojęzyczność i tłumaczenia

Rozszerzono możliwości językowe aplikacji:

- Rozbudowano skrypt `translate.py` o obsługę dowolnych par języków (wcześniej tylko z angielskiego)
- Dodano dynamiczną detekcję i przełączanie na skrypt translate.py w przypadku różnych języków
- Dodano interfejs wyboru języka wejściowego i wyjściowego (z domyślnym PL-PL)
- Zaimplementowano mapowanie kodów języków na nazwy ludzko-czytelne
- Dodano opcję "Auto-detect" dla języka wejściowego

### 8. Dodatkowe parametry dla modeli LLM

Wdrożono kontrolę parametrów modeli:

- Dodano opcję temperature (0.0-1.0) dla kontroli kreatywności
- Dodano opcję max_tokens dla kontroli długości odpowiedzi 
- Przekazywanie tych parametrów do wszystkich skryptów przetwarzających
- Aktualizację asynchronicznych funkcji convert() o nowe parametry

### 9. Usprawnienia kodu i refaktoryzacja

- Zaktualizowano dokumentację w CLAUDE.md o nowe wzorce i funkcjonalności
- Usprawniono obsługę błędów i logowanie
- Poprawiono zagnieżdżanie callbacków postępu
- Usunięto zduplikowany kod związany z modelami
- Zaktualizowano wszystkie skrypty przetwarzające o funkcje async convert() dla FastAPI

## Dalsze kroki

Na podstawie dzisiejszego refactoringu zdefiniowaliśmy dalszą wizję rozwoju w pliku `nextsteps.md`, która obejmuje:

1. [x] Ulepszenie batch processingu z możliwością wykorzystania wielu modeli
2. [x] Implementacja obsługi wielu języków i tłumaczenia
3. [ ] Dodanie nowej zakładki "Prepare Training Data" 
4. [ ] Implementację podejścia hybrydowego do multimodalności

## Uwagi techniczne

- Aktualny refactoring nie obejmuje kompleksowych zmian w strukturze folderów proponowanych w DATATREE.md
- Zachowano kompatybilność z istniejącymi funkcjami przetwarzania plików
- Uwzględniono dynamiczne wykrywanie kluczy API, które było brakującym elementem w poprzedniej wersji
- Wprowadzono podstawy pod przyszłe rozszerzenia (multimodalność, złożone transformacje danych)
- Zaimplementowany kod jest gotowy do testowania i produkcyjnego wdrożenia
- Wszystkie główne elementy Fazy 1 i Fazy 2 zostały w pełni zrealizowane
- Wszystkie skrypty zostały rozszerzone o asynchroniczny interfejs `convert()` dla integracji z FastAPI

## Wykorzystane technologie

- Python FastAPI - backend i API
- JavaScript (vanilla) - dynamiczne UI
- WebSockets - aktualizacje postępu w czasie rzeczywistym
- AsyncIO - równoległe przetwarzanie plików